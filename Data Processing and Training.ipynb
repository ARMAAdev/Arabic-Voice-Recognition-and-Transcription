{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a085edfc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2954bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential, Model, callbacks\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dropout, Bidirectional, Flatten, Dense, Input\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from jiwer import wer\n",
    "from datasets import load_dataset, load_metric\n",
    "from datasets import ClassLabel\n",
    "import random \n",
    "import re\n",
    "import pyarabic.araby as ar\n",
    "import json\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Processor, Wav2Vec2CTCTokenizer, TFAutoModelForSequenceClassification, Wav2Vec2ForCTC\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bdce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#To check if GPU is detected and being used\n",
    "tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99004f",
   "metadata": {},
   "source": [
    "# Dataset Processing (Transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5281432d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\nn\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dfTrain = pd.read_csv('CVtrain.tsv',sep='\\t')\n",
    "dfTrain[\"path\"]\n",
    "i=0\n",
    "for mp3 in dfTrain[\"path\"]:\n",
    "    mp3 = mp3.replace(\"mp3\", \"wav\")\n",
    "    dfTrain[\"path\"][i] = mp3 \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3918447",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv('CVtest.tsv',sep='\\t')\n",
    "dfTest[\"path\"]\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ddf459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      common_voice_ar_19216700.mp3\n",
       "1      common_voice_ar_23558552.mp3\n",
       "2      common_voice_ar_23675091.mp3\n",
       "3      common_voice_ar_23974261.mp3\n",
       "4      common_voice_ar_23972887.mp3\n",
       "                   ...             \n",
       "975    common_voice_ar_19541054.mp3\n",
       "976    common_voice_ar_19541055.mp3\n",
       "977    common_voice_ar_19541056.mp3\n",
       "978    common_voice_ar_19541057.mp3\n",
       "979    common_voice_ar_19541088.mp3\n",
       "Name: path, Length: 980, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest[\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b17d540c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      common_voice_ar_19216700.mp3\n",
       "1      common_voice_ar_23558552.mp3\n",
       "2      common_voice_ar_23675091.mp3\n",
       "3      common_voice_ar_23974261.mp3\n",
       "4      common_voice_ar_23972887.mp3\n",
       "                   ...             \n",
       "975    common_voice_ar_19541054.mp3\n",
       "976    common_voice_ar_19541055.mp3\n",
       "977    common_voice_ar_19541056.mp3\n",
       "978    common_voice_ar_19541057.mp3\n",
       "979    common_voice_ar_19541088.mp3\n",
       "Name: path, Length: 980, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest = pd.read_csv('CVtest.tsv',sep='\\t')\n",
    "dfTest[\"path\"]\n",
    "# dfTest = dfTest.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50071f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\nn\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for t in dfTest[\"path\"]:\n",
    "    t = t.replace(\"mp3\", \"wav\")\n",
    "    dfTest[\"path\"][i] = t \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fa3e0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      common_voice_ar_19216700.wav\n",
       "1      common_voice_ar_23558552.wav\n",
       "2      common_voice_ar_23675091.wav\n",
       "3      common_voice_ar_23974261.wav\n",
       "4      common_voice_ar_23972887.wav\n",
       "                   ...             \n",
       "975    common_voice_ar_19541054.wav\n",
       "976    common_voice_ar_19541055.wav\n",
       "977    common_voice_ar_19541056.wav\n",
       "978    common_voice_ar_19541057.wav\n",
       "979    common_voice_ar_19541088.wav\n",
       "Name: path, Length: 980, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest[\"path\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648d3483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9f67c80184f75a777443f4635bbab429ab65de4bee7c78...</td>\n",
       "      <td>C:/Users/Abdulrahman Moustafa/OneDrive/Desktop...</td>\n",
       "      <td>أَلَمْ يَعْلَمْ بِأَنَّ اللَّهَ يَرَى</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9f67c80184f75a777443f4635bbab429ab65de4bee7c78...</td>\n",
       "      <td>C:/Users/Abdulrahman Moustafa/OneDrive/Desktop...</td>\n",
       "      <td>أبي يتكلم دائما بصوت مرتفع جدا.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  9f67c80184f75a777443f4635bbab429ab65de4bee7c78...   \n",
       "1  9f67c80184f75a777443f4635bbab429ab65de4bee7c78...   \n",
       "\n",
       "                                                path  \\\n",
       "0  C:/Users/Abdulrahman Moustafa/OneDrive/Desktop...   \n",
       "1  C:/Users/Abdulrahman Moustafa/OneDrive/Desktop...   \n",
       "\n",
       "                                sentence  up_votes  down_votes  age gender  \\\n",
       "0  أَلَمْ يَعْلَمْ بِأَنَّ اللَّهَ يَرَى         2           0  NaN    NaN   \n",
       "1        أبي يتكلم دائما بصوت مرتفع جدا.         2           0  NaN    NaN   \n",
       "\n",
       "   accent locale  segment  \n",
       "0     NaN     ar      NaN  \n",
       "1     NaN     ar      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain['path'] = 'C:/Users/Abdulrahman Moustafa/OneDrive/Desktop/NN project/wavFiles/' + dfTrain['path']\n",
    "dfTrain.to_csv('CVtrain.csv',sep='\\t',index=False)\n",
    "dfTrain[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6ee1f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      common_voice_ar_19216700.wav\n",
       "1      common_voice_ar_23558552.wav\n",
       "2      common_voice_ar_23675091.wav\n",
       "3      common_voice_ar_23974261.wav\n",
       "4      common_voice_ar_23972887.wav\n",
       "                   ...             \n",
       "975    common_voice_ar_19541054.wav\n",
       "976    common_voice_ar_19541055.wav\n",
       "977    common_voice_ar_19541056.wav\n",
       "978    common_voice_ar_19541057.wav\n",
       "979    common_voice_ar_19541088.wav\n",
       "Name: path, Length: 980, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest[\"path\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea02eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0cae0344c4bc6379e9109c5925bc9f94a5e8b17a431058...</td>\n",
       "      <td>C:/Users/Abdulrahman Moustafa/OneDrive/Desktop...</td>\n",
       "      <td>ألديك قلم ؟</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0dd9767be01ce747c4656c72cf8a5d8ded3f191a78eff5...</td>\n",
       "      <td>C:/Users/Abdulrahman Moustafa/OneDrive/Desktop...</td>\n",
       "      <td>ليست هناك مسافة على هذه الأرض أبعد من يوم أمس.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  0cae0344c4bc6379e9109c5925bc9f94a5e8b17a431058...   \n",
       "1  0dd9767be01ce747c4656c72cf8a5d8ded3f191a78eff5...   \n",
       "\n",
       "                                                path  \\\n",
       "0  C:/Users/Abdulrahman Moustafa/OneDrive/Desktop...   \n",
       "1  C:/Users/Abdulrahman Moustafa/OneDrive/Desktop...   \n",
       "\n",
       "                                         sentence  up_votes  down_votes  \\\n",
       "0                                     ألديك قلم ؟         2           1   \n",
       "1  ليست هناك مسافة على هذه الأرض أبعد من يوم أمس.         2           0   \n",
       "\n",
       "        age gender  accent locale segment  \n",
       "0       NaN    NaN     NaN     ar     NaN  \n",
       "1  thirties   male     NaN     ar     NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest['path'] = \"C:/Users/Abdulrahman Moustafa/OneDrive/Desktop/NN project/wavFiles/\" + dfTest['path']\n",
    "dfTest.to_csv('CVtest.csv',sep='\\t',index=False)\n",
    "dfTest[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4830e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of all mp3 files that will be used, the folder contains about 63,000 mp3 files, we will filter them to the ones we will\n",
    "#use and delete the rest\n",
    "#after filtering we will convert them to wav files to be able to easily load them using librosa\n",
    "# mp3list = []\n",
    "# mp3list.extend(list(dfTest['path']))\n",
    "# mp3list.extend(list(dfTrain['path']))\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "# from os import path\n",
    "# for mp3 in mp3list:\n",
    "#     src_path = mp3\n",
    "#     dst_path = r\"C:\\Users\\Abdulrahman Moustafa\\OneDrive\\Desktop\\NN project\\CVwavs\"\n",
    "#     shutil.move(src_path, dst_path)\n",
    "\n",
    "# from pathlib import Path\n",
    "# for mp3 in mp3list2:\n",
    "#     mp3 = Path(mp3)\n",
    "#     mp3.rename(mp3.with_suffix('.wav'))\n",
    "\n",
    "#Note: This code was done once only to change the file formats, once they are changed no need to run it, uncomment if you want to change mp3 to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da898227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2aa54a843f4238f4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/Abdulrahman Moustafa/AppData/Roaming/SPB_Data/.cache/huggingface/datasets/csv/default-2aa54a843f4238f4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5da34314acf4ab6959bcb014a1080c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f71eb55fe4f4c80a7396378081a6128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/Abdulrahman Moustafa/AppData/Roaming/SPB_Data/.cache/huggingface/datasets/csv/default-2aa54a843f4238f4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6018e65c547d4de48ab4ff8db26aa576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e0c4e5310dc665c4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/Abdulrahman Moustafa/AppData/Roaming/SPB_Data/.cache/huggingface/datasets/csv/default-e0c4e5310dc665c4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e2e3f6eb3a4fda854a96604bd7f6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bfe1a0005244ac8a7809ec697af8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/Abdulrahman Moustafa/AppData/Roaming/SPB_Data/.cache/huggingface/datasets/csv/default-e0c4e5310dc665c4/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82010921baed4aef864356df4692c7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataTrain = load_dataset('csv',data_files=['CVtrain.csv'],delimiter='\\t')\n",
    "dataTrain = dataTrain['train'].remove_columns(['client_id', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'])\n",
    "\n",
    "dataTest = load_dataset('csv',data_files=['CVtest.csv'],delimiter='\\t')\n",
    "dataTest = dataTest['train'].remove_columns(['client_id', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0cd8576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'C:/Users/Abdulrahman Moustafa/OneDrive/Desktop/NN project/wavFiles/common_voice_ar_24032939.wav',\n",
       " 'sentence': 'أَلَمْ يَعْلَمْ بِأَنَّ اللَّهَ يَرَى'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd51047",
   "metadata": {},
   "source": [
    "# Text Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a02e257b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to display random data from our dataset to check our data everytime we make a change\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78180463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>إِنَّ الَّذِينَ يَرْمُونَ الْمُحْصَنَاتِ الْغَافِلَاتِ الْمُؤْمِنَاتِ لُعِنُوا فِي الدُّنْيَا وَالْآخِرَةِ وَلَهُمْ عَذَابٌ عَظِيمٌ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>حبيبي أقدّم عمري لكَ هديّة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وأن المساجد لله فلا تدعوا مع الله أحدا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>وَكَذَلِكَ نُصَرِّفُ الْآيَاتِ وَلِيَقُولُوا دَرَسْتَ وَلِنُبَيِّنَهُ لِقَوْمٍ يَعْلَمُونَ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ان في ثورتنا فصل الخطاب</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataTrain.remove_columns([\"path\"]), num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b58b0e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc13a58a77324aac9dd07486855c4d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2498 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b089127eee45cca57972c4305f2104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/980 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normalization of sentences by removing diatrics and punctuations\n",
    "chars_to_ignore_regex = '[\\,\\؟\\.\\!\\-\\;\\:\\'\\\"\\☭\\«\\»\\؛\\—\\ـ\\_\\،\\“\\%\\‘\\”\\�]'\n",
    "def remove_diatrics(ds):\n",
    "    ds[\"sentence\"] = re.sub(chars_to_ignore_regex, '', ds[\"sentence\"]).lower() + \" \"\n",
    "    ds[\"sentence\"] = ar.strip_diacritics(ds[\"sentence\"])\n",
    "    ds[\"sentence\"] = ds[\"sentence\"].translate(str.maketrans('', '', string.punctuation))\n",
    "    return ds\n",
    "\n",
    "dataTrain = dataTrain.map(remove_diatrics)\n",
    "dataTest = dataTest.map(remove_diatrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ff95d7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>هل يجب أن تذهب إلى مكتب البريد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ثم لعله لا يفطن لشأنه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وملبسه حرام وغذي بالحرام فأنى يستجاب له</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>هل حقا أنت أميرة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>إن إلهكم لواحد</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataTrain.remove_columns([\"path\"]), num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e24d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting all letters from our dataset\n",
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"sentence\"]) \n",
    "    vocab = list(set(all_text)) #set doesn't allow duplicates\n",
    "    return {\"vocab\": [vocab], \"all_text\": [all_text]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf43f016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83dd9a6fff84501bfa2723b319fe6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160f6ff153374869b2399961162d7e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_train = dataTrain.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=dataTrain.column_names)\n",
    "vocab_test = dataTest.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=dataTest.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "681aed4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ك',\n",
       " 'ه',\n",
       " 'ش',\n",
       " 'ض',\n",
       " 'م',\n",
       " 'ة',\n",
       " 'ا',\n",
       " 'ن',\n",
       " 'ت',\n",
       " 'ط',\n",
       " 'د',\n",
       " 'ز',\n",
       " 'أ',\n",
       " 'إ',\n",
       " ' ',\n",
       " 'ق',\n",
       " 'ی',\n",
       " 'خ',\n",
       " 'ک',\n",
       " 'ى',\n",
       " 'ف',\n",
       " 'ظ',\n",
       " 'غ',\n",
       " 'ؤ',\n",
       " 'س',\n",
       " 'ذ',\n",
       " 'ص',\n",
       " 'ي',\n",
       " 'و',\n",
       " 'ء',\n",
       " 'ع',\n",
       " 'ح',\n",
       " 'ج',\n",
       " 'ث',\n",
       " 'آ',\n",
       " 'ر',\n",
       " 'ئ',\n",
       " 'ب',\n",
       " 'ل']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = list(set(vocab_train[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0]))\n",
    "vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e9dc000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ك': 0,\n",
       " 'ه': 1,\n",
       " 'ش': 2,\n",
       " 'ض': 3,\n",
       " 'م': 4,\n",
       " 'ة': 5,\n",
       " 'ا': 6,\n",
       " 'ن': 7,\n",
       " 'ت': 8,\n",
       " 'ط': 9,\n",
       " 'د': 10,\n",
       " 'ز': 11,\n",
       " 'أ': 12,\n",
       " 'إ': 13,\n",
       " ' ': 14,\n",
       " 'ق': 15,\n",
       " 'ی': 16,\n",
       " 'خ': 17,\n",
       " 'ک': 18,\n",
       " 'ى': 19,\n",
       " 'ف': 20,\n",
       " 'ظ': 21,\n",
       " 'غ': 22,\n",
       " 'ؤ': 23,\n",
       " 'س': 24,\n",
       " 'ذ': 25,\n",
       " 'ص': 26,\n",
       " 'ي': 27,\n",
       " 'و': 28,\n",
       " 'ء': 29,\n",
       " 'ع': 30,\n",
       " 'ح': 31,\n",
       " 'ج': 32,\n",
       " 'ث': 33,\n",
       " 'آ': 34,\n",
       " 'ر': 35,\n",
       " 'ئ': 36,\n",
       " 'ب': 37,\n",
       " 'ل': 38}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary to map every letter with an integer\n",
    "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eddfe64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to replace any spaces with |\n",
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d43f28b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"[UNK]\"] = len(vocab_dict) #UNK = unknown token, important part of a language model, replaces unknown letters with UNK\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict) #adding padding to keep length consistent while training our language model\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edaa9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear layer that we will add on top of the pretrained XLSR-Wav2Vec2 checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b52053e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ك': 0,\n",
       " 'ه': 1,\n",
       " 'ش': 2,\n",
       " 'ض': 3,\n",
       " 'م': 4,\n",
       " 'ة': 5,\n",
       " 'ا': 6,\n",
       " 'ن': 7,\n",
       " 'ت': 8,\n",
       " 'ط': 9,\n",
       " 'د': 10,\n",
       " 'ز': 11,\n",
       " 'أ': 12,\n",
       " 'إ': 13,\n",
       " 'ق': 15,\n",
       " 'ی': 16,\n",
       " 'خ': 17,\n",
       " 'ک': 18,\n",
       " 'ى': 19,\n",
       " 'ف': 20,\n",
       " 'ظ': 21,\n",
       " 'غ': 22,\n",
       " 'ؤ': 23,\n",
       " 'س': 24,\n",
       " 'ذ': 25,\n",
       " 'ص': 26,\n",
       " 'ي': 27,\n",
       " 'و': 28,\n",
       " 'ء': 29,\n",
       " 'ع': 30,\n",
       " 'ح': 31,\n",
       " 'ج': 32,\n",
       " 'ث': 33,\n",
       " 'آ': 34,\n",
       " 'ر': 35,\n",
       " 'ئ': 36,\n",
       " 'ب': 37,\n",
       " 'ل': 38,\n",
       " '|': 14,\n",
       " '[UNK]': 39,\n",
       " '[PAD]': 40}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6ed35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving our language model (dictionary) as a json file as json is good for storing dictionaries \n",
    "vocab_file = open(\"vocab.json\", 'w')\n",
    "json.dump(vocab_dict, vocab_file) #saving vocab_dict in vocab_file\n",
    "vocab_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f65090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wav2Vec2 tokenizer is pretrained model that contains a pretrained tokenizer, it uses CTC which is an algo used to train DNN in SR\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "695b7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wav2Vec2 feature extractor\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "350a3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wav2Vec2 Processor links the tokenizer and the feature_extractor into one package that acts as a language processor\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48fec3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the directory to save our language model:\n",
    "lang_model_dir = \"C:/Users/Abdulrahman Moustafa/OneDrive/Desktop/NN project/Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a688112",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained(lang_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae3332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a02336cb",
   "metadata": {},
   "source": [
    "# Audio Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ddab54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(ds):\n",
    "    speech_array, sampling_rate = torchaudio.load(ds[\"path\"])\n",
    "    ds[\"speech\"] = speech_array[0].numpy()\n",
    "    ds[\"sampling_rate\"] = sampling_rate\n",
    "    ds[\"target_text\"] = ds[\"sentence\"]\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6b9eef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4490aba818eb45b98e007167fc6e4367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2498 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717c05d5e1e245148b73b61a98587c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/980 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataTrain2 = dataTrain.map(speech_file_to_array_fn, remove_columns=dataTrain.column_names)\n",
    "dataTest2 = dataTest.map(speech_file_to_array_fn, remove_columns=dataTest.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60451b2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c7c15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(ds):\n",
    "    ds[\"speech\"] = librosa.resample(np.asarray(ds[\"speech\"]), 48_000, 16_000)\n",
    "    ds[\"sampling_rate\"] = 16_000\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5aec6258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd237123c07b4e06a244dfd6d7173813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2498 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\nn\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Pass orig_sr=48000, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  \n",
      "C:\\anaconda\\envs\\nn\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Pass orig_sr=48000, target_sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6315c2abfa46cbb8ad56fac706248e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/980 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataTrain3 = dataTrain2.map(resample)\n",
    "dataTest3 = dataTest2.map(resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67f1b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # check that all files have the correct sampling rate\n",
    "    assert (\n",
    "        len(set(batch[\"sampling_rate\"])) == 1\n",
    "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e7eec1f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Abdulrahman Moustafa\\AppData\\Roaming\\SPB_Data\\.cache\\huggingface\\datasets\\csv\\default-2aa54a843f4238f4\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-47d10f9730c13c0b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Abdulrahman Moustafa\\AppData\\Roaming\\SPB_Data\\.cache\\huggingface\\datasets\\csv\\default-e0c4e5310dc665c4\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-63e2eac2d7477f76.arrow\n"
     ]
    }
   ],
   "source": [
    "dataTrain4 = dataTrain3.map(prepare_dataset, remove_columns=dataTrain3.column_names, batch_size=8, batched=True)\n",
    "dataTest4 = dataTest3.map(prepare_dataset, remove_columns=dataTest3.column_names, batch_size=8, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fc9ec6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = dataTrain4[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42186b04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in yTrain:\n",
    "    yTrain[yTrain.index(i)] = keras.utils.to_categorical(i, num_classes=(len(vocab_dict)), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = np.array(dataTrain4[\"input_values\"]).reshape(-1,16000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52be7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_desired, y_pred):\n",
    "    #calculating the training time loss value\n",
    "    batch_len = tf.cast(tf.shape(y_desired[0]), dtype = \"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype = \"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_desired)[1], dtype = \"int64\")\n",
    "    \n",
    "    input_length = input_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n",
    "    label_length = label_length * tf.ones(shape = (batch_len, 1), dtype = \"int64\")\n",
    "    loss = keras.backend.ctc_batch_cost(y_desired, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b6bcb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stop determines when the model can't improve further and stops it, checkpoint will save the model after stopping \n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, min_delta=0.0001) \n",
    "checkpoint = callbacks.ModelCheckpoint('arabicSR.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368bfa9",
   "metadata": {},
   "source": [
    "# Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da7f0294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 16000, 1)          4         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 15988, 8)          112       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5329, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5329, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5319, 16)          1424      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1773, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1773, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1765, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 588, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 588, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 588, 32)           128       \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 588, 128)          124416    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 588, 128)          198144    \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 128)               198144    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 41)                10537     \n",
      "=================================================================\n",
      "Total params: 571,085\n",
      "Trainable params: 570,763\n",
      "Non-trainable params: 322\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Input(shape=(16000,1))) #sampling rate = 16000 input are features\n",
    "\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.0001, center=True, scale=True))\n",
    "\n",
    "#First Conv1D layer\n",
    "model.add(Conv1D(8, 13, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Second Conv1D layer\n",
    "model.add(Conv1D(16, 11, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Third Conv1D layer\n",
    "model.add(Conv1D(32, 9, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True))\n",
    "model.add(Bidirectional(tf.compat.v1.keras.layers.CuDNNGRU(128, return_sequences=True), merge_mode='sum'))\n",
    "model.add(Bidirectional(tf.compat.v1.keras.layers.CuDNNGRU(128, return_sequences=True), merge_mode='sum'))\n",
    "model.add(Bidirectional(tf.compat.v1.keras.layers.CuDNNGRU(128, return_sequences=False), merge_mode='sum'))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True))\n",
    "\n",
    "#Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "#Dense Layer 1\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#output layer          \n",
    "model.add(Dense(len(vocab_dict), activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2e4f89c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer, padding=True)\n",
    "\n",
    "tf_dataTrain = dataTrain4.to_tf_dataset(\n",
    "   columns=['input_values'],\n",
    "   label_cols = ['labels'],\n",
    "   shuffle=True,\n",
    "   batch_size=16,\n",
    "   collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_dataTest = dataTest4.to_tf_dataset(\n",
    "   columns=['input_values'],\n",
    "   label_cols = ['labels'],\n",
    "   shuffle=True,\n",
    "   batch_size=16,\n",
    "   collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1421a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=CTCLoss, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "11fb9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x=xTrain, y=yTrain, epochs=10, callbacks=[early_stop, checkpoint], batch_size=64, verbose=1, validation_data=(dataTest[\"input_values\"], dataTest[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To test the performance of the network, we plot the loss and validation curves\n",
    "pyplot.plot(hist.history['loss'], label='train')\n",
    "pyplot.plot(hist.history['val_loss'], label='test')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We take a pretrained model and remove its (head) output layer \n",
    "transfer_learning = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "model2 = TFAutoModelForSequenceClassification.from_pretrained(transfer_learning, num_labels=len(vocab_dict))\n",
    "model2.compile(optimizer=\"adam\", loss=SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "hist2 = model2.fit(tf_dataTrain, validation_data=tf_dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(hist2.history['loss'], label='train')\n",
    "pyplot.plot(hist2.history['val_loss'], label='test')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa96a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cdcfb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the word error rate \n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4ab10994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Abdulrahman Moustafa\\AppData\\Roaming\\SPB_Data/.cache\\huggingface\\hub\\models--facebook--wav2vec2-large-xlsr-53\\snapshots\\c3f9d884181a224a6ac87bf8885c84d1cff3384f\\config.json\n",
      "Model config Wav2Vec2Config {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForPreTraining\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_channel_selection\": \"static\",\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.075,\n",
      "  \"mask_time_selection\": \"static\",\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c840cc0970bb4810b669c24a354566df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Abdulrahman Moustafa\\AppData\\Roaming\\SPB_Data/.cache\\huggingface\\hub\\models--facebook--wav2vec2-large-xlsr-53\\snapshots\\c3f9d884181a224a6ac87bf8885c84d1cff3384f\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['project_hid.weight', 'quantizer.codevectors', 'quantizer.weight_proj.weight', 'quantizer.weight_proj.bias', 'project_q.bias', 'project_q.weight', 'project_hid.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model3 = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81952a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "#training using a trainer from transformers\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model3,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataTrain4,\n",
    "    eval_dataset=dataTest4,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93121f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"myModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a3049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
